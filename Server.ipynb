{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Server.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "15bH1TBjcM-W",
        "colab_type": "code",
        "outputId": "d663e336-d854-4da3-e389-951bd8550f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# All codes which are done for setting up the server (Setting up the server environment, Installation of model dependencies and etc)\n",
        "\n",
        "#########################################################################\n",
        "# OCR part\n",
        "#########################################################################\n",
        "!sudo apt install tesseract-ocr\n",
        "\n",
        "\n",
        "#########################################################################\n",
        "# Object Detection part\n",
        "#########################################################################\n",
        "# install dependencies\n",
        "def install():\n",
        "  !pip install Flask\n",
        "  !pip install flask-ngrok\n",
        "  !pip install -U torch torchvision cython\n",
        "  !pip install -U 'git+https://github.com/facebookresearch/fvcore.git' 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
        "  !git clone https://github.com/facebookresearch/detectron2 detectron2_repo\n",
        "  !pip install -e detectron2_repo\n",
        "\n",
        "install()\n",
        "\n",
        "# After install\n",
        "# You may need to restart your runtime prior to this, to let your installation take effect\n",
        "# Some basic setup\n",
        "# Setup detectron2 logger\n",
        "import torch, torchvision\n",
        "torch.__version__\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "from collections import OrderedDict\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "# make pretrained model object\n",
        "predictor = None\n",
        "cfg = None\n",
        "def setup():\n",
        "  global cfg\n",
        "  global predictor\n",
        "  cfg = get_cfg()\n",
        "  cfg.merge_from_file(\"./detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "  cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n",
        "  # Find a model from detectron2's model zoo. You can either use the https://dl.fbaipublicfiles.... url, or use the following shorthand\n",
        "  cfg.MODEL.WEIGHTS = \"detectron2://COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\"\n",
        "  predictor = DefaultPredictor(cfg)\n",
        "\n",
        "setup()\n",
        "\n",
        "\n",
        "#########################################################################\n",
        "# TTS part\n",
        "#########################################################################\n",
        "# def install_tts():\n",
        "#   # Clone git repo\n",
        "#   !git clone https://github.com/CorentinJ/Real-Time-Voice-Cloning.git\n",
        "#   %cd Real-Time-Voice-Cloning/\n",
        "#   # Install dependencies\n",
        "#   !pip install -q -r requirements.txt\n",
        "#   !apt-get install -qq libportaudio2\n",
        "#   # Download dataset\n",
        "#   !gdown https://drive.google.com/uc?id=1n1sPXvT34yXFLT47QZA6FIRGrwMeSsZc\n",
        "#   !unzip pretrained.zip\n",
        "#   !gdown https://drive.google.com/uc?id=1eZNxBYyf9Rg7i7wwSpIyD91uaxkGqsPl\n",
        "\n",
        "# install_tts()\n",
        "  \n",
        "# # Code for recording audio from the browser\n",
        "\n",
        "# from IPython.display import Javascript\n",
        "# from google.colab import output\n",
        "# from base64 import b64decode\n",
        "# import IPython\n",
        "# import uuid\n",
        "# from google.colab import output\n",
        "# from IPython.display import Audio\n",
        "# from IPython.utils import io\n",
        "# from synthesizer.inference import Synthesizer\n",
        "# from encoder import inference as encoder\n",
        "# from vocoder import inference as vocoder\n",
        "# from pathlib import Path\n",
        "# import numpy as np\n",
        "# import librosa\n",
        "# synthesizer = None\n",
        "# def setup_tts():\n",
        "#   global synthesizer\n",
        "#   print(\"inside set up\")\n",
        "#   encoder_weights = Path(\"encoder/saved_models/pretrained.pt\")\n",
        "#   vocoder_weights = Path(\"vocoder/saved_models/pretrained/pretrained.pt\")\n",
        "#   syn_dir = Path(\"synthesizer/saved_models/logs-pretrained/taco_pretrained\")\n",
        "#   encoder.load_model(encoder_weights)\n",
        "#   synthesizer = Synthesizer(syn_dir)\n",
        "#   vocoder.load_model(vocoder_weights)\n",
        "# setup_tts()\n",
        "\n",
        "\n",
        "#########################################################################\n",
        "# Image Captioning part\n",
        "#########################################################################\n",
        "#실제로 할 때는 url 관련된 부분 지우고, IMAGE_FILE 변경, replace 경로 변경\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from tempfile import mkstemp\n",
        "from shutil import move\n",
        "from os import fdopen, remove\n",
        "\n",
        "\n",
        "def replace(file_path, pattern, subst):\n",
        "    #Create temp file\n",
        "    fh, abs_path = mkstemp()\n",
        "    with fdopen(fh,'w') as new_file:\n",
        "        with open(file_path) as old_file:\n",
        "            for line in old_file:\n",
        "                new_file.write(line.replace(pattern, subst))\n",
        "            old_file.close()\n",
        "        new_file.close()\n",
        "    #Remove original file\n",
        "    remove(file_path)\n",
        "    #Move new file\n",
        "    move(abs_path, file_path)\n",
        "\n",
        "def modify_files():\n",
        "    OLD_CHECKPOINT_FILE = \"/content/Pretrained-Show-and-Tell-model/model.ckpt-2000000\"\n",
        "    NEW_CHECKPOINT_FILE = \"/content/Pretrained-Show-and-Tell-model/model2.ckpt-2000000\"\n",
        "\n",
        "    import tensorflow as tf\n",
        "    vars_to_rename = {\n",
        "        \"lstm/basic_lstm_cell/weights\": \"lstm/basic_lstm_cell/kernel\",\n",
        "        \"lstm/basic_lstm_cell/biases\": \"lstm/basic_lstm_cell/bias\",\n",
        "    }\n",
        "    new_checkpoint_vars = {}\n",
        "    reader = tf.train.NewCheckpointReader(OLD_CHECKPOINT_FILE)\n",
        "    for old_name in reader.get_variable_to_shape_map():\n",
        "        if old_name in vars_to_rename:\n",
        "            new_name = vars_to_rename[old_name]\n",
        "    else:\n",
        "        new_name = old_name\n",
        "    new_checkpoint_vars[new_name] = tf.Variable(reader.get_tensor(old_name))\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    saver = tf.train.Saver(new_checkpoint_vars)\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        saver.save(sess, NEW_CHECKPOINT_FILE)\n",
        "\n",
        "def setup_img_captioning():\n",
        "    # Pre-trained model git repo.\n",
        "    %cd /content\n",
        "    !git clone https://github.com/KranthiGV/Pretrained-Show-and-Tell-model.git\n",
        "\n",
        "    # im2txt git repo.\n",
        "    !git init img_caption\n",
        "    %cd img_caption\n",
        "    %ls .\n",
        "    !git config core.sparseCheckout true\n",
        "    !git remote add -f origin https://github.com/tensorflow/models.git\n",
        "    !echo \"research/im2txt\" >> .git/info/sparse-checkout\n",
        "    !git pull origin master\n",
        "\n",
        "    %cd /content\n",
        "    # download packages, libraries\n",
        "    !pip install virtualenv\n",
        "    !virtualenv venv\n",
        "    !virtualenv -p /usr/bin/python2.7 --distribute temp-python\n",
        "    # os.system(\"virtualenv -p /usr/bin/python2.7 --distribute temp-python\")\n",
        "    !source temp-python/bin/activate\n",
        "    # !python -c 'import sys; print(sys.version_info[:])'\n",
        "    !sudo apt autoremove\n",
        "    !sudo apt-get install g++ unzip zip\n",
        "    !sudo apt autoremove\n",
        "    !sudo apt-get install openjdk-11-jdk\n",
        "    !wget https://github.com/bazelbuild/bazel/releases/download/1.0.0/bazel-1.0.0-installer-linux-x86_64.sh\n",
        "    !chmod +x bazel-1.0.0-installer-linux-x86_64.sh\n",
        "    !./bazel-1.0.0-installer-linux-x86_64.sh --user\n",
        "    os.environ['PATH'] += ':/root/bin'\n",
        "    !pip install tensorflow==1.0.0\n",
        "    !pip install numpy\n",
        "    !pip install nltk\n",
        "    !python -m nltk.downloader punkt\n",
        "\n",
        "    !pip install requests\n",
        "\n",
        "    # download checkpoint (2M iteration)\n",
        "    from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "    gdd.download_file_from_google_drive(file_id='0B3laN3vvvSD2WWxuR3VRQzhycWM',\n",
        "                                        dest_path='/content/Pretrained-Show-and-Tell-model/model.ckpt-1000000.data-00000-of-00001')\n",
        "    gdd.download_file_from_google_drive(file_id='0B3laN3vvvSD2T1RPeDA5djJ6bFE',\n",
        "                                        dest_path='/content/Pretrained-Show-and-Tell-model/model.ckpt-2000000.data-00000-of-00001')\n",
        "    \n",
        "    # solved mismatch problem of variable name in tensorflow graph\n",
        "    replace(\"/content/img_caption/research/im2txt/im2txt/inference_utils/caption_generator.py\"\n",
        "    , '[:-self.beam_size]', '')\n",
        "\n",
        "    # modify_files()\n",
        "    replace(\"/content/img_caption/research/im2txt/im2txt/run_inference.py\", '      for i, caption in enumerate(captions):', '      f=open(\"/result.txt\", mode=\"w+\", encoding=\"utf-8\")')\n",
        "    replace(\"/content/img_caption/research/im2txt/im2txt/run_inference.py\", '        sentence = [vocab.id_to_word(w) for w in caption.sentence[1:-1]]', '      sentence = [vocab.id_to_word(w) for w in captions[0].sentence[1:-1]]')\n",
        "    replace(\"/content/img_caption/research/im2txt/im2txt/run_inference.py\", '        sentence = \" \".join(sentence)', '      sentence = \" \".join(sentence)\\n      f.write(sentence)\\n      f.close()')\n",
        "    replace(\"/content/img_caption/research/im2txt/im2txt/run_inference.py\", '        print(\"  %d) %s (p=%f)\" % (i, sentence, math.exp(caption.logprob)))', '      print(\"  %d) %s (p=%f)\" % (0, sentence, math.exp(captions[0].logprob)))')\n",
        "\n",
        "\n",
        "setup_img_captioning()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (1.1.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask) (0.16.0)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask) (2.10.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask) (1.1.1)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.6/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (2.21.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.6/dist-packages (from flask-ngrok) (1.1.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (2.10.3)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (7.0)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from Flask>=0.8->flask-ngrok) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->Flask>=0.8->flask-ngrok) (1.1.1)\n",
            "Requirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already up-to-date: torchvision in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already up-to-date: cython in /usr/local/lib/python3.6/dist-packages (0.29.14)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from torch) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Collecting git+https://github.com/facebookresearch/fvcore.git\n",
            "  Cloning https://github.com/facebookresearch/fvcore.git to /tmp/pip-req-build-apab0j8e\n",
            "  Running command git clone -q https://github.com/facebookresearch/fvcore.git /tmp/pip-req-build-apab0j8e\n",
            "Collecting git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI\n",
            "  Cloning https://github.com/cocodataset/cocoapi.git to /tmp/pip-req-build-ibqcxtbe\n",
            "  Running command git clone -q https://github.com/cocodataset/cocoapi.git /tmp/pip-req-build-ibqcxtbe\n",
            "Requirement already satisfied, skipping upgrade: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (0.1.6)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (5.1.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (4.40.0)\n",
            "Requirement already satisfied, skipping upgrade: portalocker in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (1.5.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from fvcore==0.1) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (41.6.0)\n",
            "Requirement already satisfied, skipping upgrade: cython>=0.27.3 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (0.29.14)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools==2.0) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.4.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.1.0->pycocotools==2.0) (2.6.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools==2.0) (1.12.0)\n",
            "Building wheels for collected packages: fvcore, pycocotools\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1-cp36-none-any.whl size=49203 sha256=292b9c586804ced56fdff217ba6197745380ec607d7dc05f8c391701cde0a2a9\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pdh32p76/wheels/48/53/79/3c6485543a4455a0006f5db590ab9957622b6227011941de06\n",
            "  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycocotools: filename=pycocotools-2.0-cp36-cp36m-linux_x86_64.whl size=275254 sha256=077484f6c3bcc5bcdbdd298ae46eaf3e7cf29ab25afbaef5c49d53e0f5392127\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-pdh32p76/wheels/90/51/41/646daf401c3bc408ff10de34ec76587a9b3ebfac8d21ca5c3a\n",
            "Successfully built fvcore pycocotools\n",
            "Installing collected packages: fvcore, pycocotools\n",
            "  Found existing installation: fvcore 0.1\n",
            "    Uninstalling fvcore-0.1:\n",
            "      Successfully uninstalled fvcore-0.1\n",
            "  Found existing installation: pycocotools 2.0\n",
            "    Uninstalling pycocotools-2.0:\n",
            "      Successfully uninstalled pycocotools-2.0\n",
            "Successfully installed fvcore-0.1 pycocotools-2.0\n",
            "fatal: destination path 'detectron2_repo' already exists and is not an empty directory.\n",
            "Obtaining file:///content/detectron2_repo\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (1.1.0)\n",
            "Requirement already satisfied: Pillow>=6.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (6.2.1)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (0.1.6)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (0.8.5)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (3.1.1)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (4.40.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (1.15.0)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.6/dist-packages (from detectron2==0.1) (1.1.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs>=0.1.6->detectron2==0.1) (5.1.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1) (1.17.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1) (2.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->detectron2==0.1) (2.4.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (3.1.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (41.6.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (0.16.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (1.15.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (1.12.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (0.33.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->detectron2==0.1) (3.10.0)\n",
            "Installing collected packages: detectron2\n",
            "  Found existing installation: detectron2 0.1\n",
            "    Can't uninstall 'detectron2'. No files were found to uninstall.\n",
            "  Running setup.py develop for detectron2\n",
            "Successfully installed detectron2\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[12/01 14:38:39 d2.config.compat]: \u001b[0mConfig './detectron2_repo/configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "model_final_f10217.pkl: 178MB [00:11, 16.1MB/s]                           \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Cloning into 'Pretrained-Show-and-Tell-model'...\n",
            "remote: Enumerating objects: 49, done.\u001b[K\n",
            "remote: Total 49 (delta 0), reused 0 (delta 0), pack-reused 49\u001b[K\n",
            "Unpacking objects: 100% (49/49), done.\n",
            "Initialized empty Git repository in /content/img_caption/.git/\n",
            "/content/img_caption\n",
            "Updating origin\n",
            "remote: Enumerating objects: 896, done.\u001b[K\n",
            "remote: Counting objects: 100% (896/896), done.\u001b[K\n",
            "remote: Compressing objects: 100% (527/527), done.\u001b[K\n",
            "remote: Total 32953 (delta 483), reused 604 (delta 368), pack-reused 32057\u001b[K\n",
            "Receiving objects: 100% (32953/32953), 512.26 MiB | 35.03 MiB/s, done.\n",
            "Resolving deltas: 100% (20792/20792), done.\n",
            "From https://github.com/tensorflow/models\n",
            " * [new branch]      BarretZoph-patch-1      -> origin/BarretZoph-patch-1\n",
            " * [new branch]      BarretZoph-patch-2      -> origin/BarretZoph-patch-2\n",
            " * [new branch]      MarkDaoust-patch-1      -> origin/MarkDaoust-patch-1\n",
            " * [new branch]      YknZhu-patch-1          -> origin/YknZhu-patch-1\n",
            " * [new branch]      YknZhu-patch-2          -> origin/YknZhu-patch-2\n",
            " * [new branch]      YknZhu-patch-2-1        -> origin/YknZhu-patch-2-1\n",
            " * [new branch]      YknZhu-patch-3          -> origin/YknZhu-patch-3\n",
            " * [new branch]      YknZhu-patch-4          -> origin/YknZhu-patch-4\n",
            " * [new branch]      YknZhu-patch-5          -> origin/YknZhu-patch-5\n",
            " * [new branch]      achowdhery-patch-1      -> origin/achowdhery-patch-1\n",
            " * [new branch]      achowdhery-patch-fpnlite-config -> origin/achowdhery-patch-fpnlite-config\n",
            " * [new branch]      add-flags-info          -> origin/add-flags-info\n",
            " * [new branch]      add-loss                -> origin/add-loss\n",
            " * [new branch]      add-metric              -> origin/add-metric\n",
            " * [new branch]      anjs-fix-lint           -> origin/anjs-fix-lint\n",
            " * [new branch]      benchmark-number        -> origin/benchmark-number\n",
            " * [new branch]      callstack-sampler       -> origin/callstack-sampler\n",
            " * [new branch]      cifar-keras-synth-data  -> origin/cifar-keras-synth-data\n",
            " * [new branch]      cl_250423625            -> origin/cl_250423625\n",
            " * [new branch]      ctl-benchmarks          -> origin/ctl-benchmarks\n",
            " * [new branch]      data-cache              -> origin/data-cache\n",
            " * [new branch]      distrat-prototype       -> origin/distrat-prototype\n",
            " * [new branch]      feat/contrib-data       -> origin/feat/contrib-data\n",
            " * [new branch]      feat/extended_prototype -> origin/feat/extended_prototype\n",
            " * [new branch]      feat/microbenchmarks    -> origin/feat/microbenchmarks\n",
            " * [new branch]      feature/kubeflow-testing -> origin/feature/kubeflow-testing\n",
            " * [new branch]      fix-lint                -> origin/fix-lint\n",
            " * [new branch]      fix-ncf-benchmark       -> origin/fix-ncf-benchmark\n",
            " * [new branch]      fix/bert_startup        -> origin/fix/bert_startup\n",
            " * [new branch]      fix/clear-devices       -> origin/fix/clear-devices\n",
            " * [new branch]      fix/more_testing        -> origin/fix/more_testing\n",
            " * [new branch]      fix/reduce_test_batch_size -> origin/fix/reduce_test_batch_size\n",
            " * [new branch]      guptapriya-ncf-keras    -> origin/guptapriya-ncf-keras\n",
            " * [new branch]      guptapriya-patch-1      -> origin/guptapriya-patch-1\n",
            " * [new branch]      guptapriya-patch-10     -> origin/guptapriya-patch-10\n",
            " * [new branch]      guptapriya-patch-11     -> origin/guptapriya-patch-11\n",
            " * [new branch]      guptapriya-patch-12     -> origin/guptapriya-patch-12\n",
            " * [new branch]      guptapriya-patch-13     -> origin/guptapriya-patch-13\n",
            " * [new branch]      guptapriya-patch-14     -> origin/guptapriya-patch-14\n",
            " * [new branch]      guptapriya-patch-15     -> origin/guptapriya-patch-15\n",
            " * [new branch]      guptapriya-patch-2      -> origin/guptapriya-patch-2\n",
            " * [new branch]      guptapriya-patch-3      -> origin/guptapriya-patch-3\n",
            " * [new branch]      guptapriya-patch-4      -> origin/guptapriya-patch-4\n",
            " * [new branch]      guptapriya-patch-5      -> origin/guptapriya-patch-5\n",
            " * [new branch]      guptapriya-patch-6      -> origin/guptapriya-patch-6\n",
            " * [new branch]      guptapriya-patch-7      -> origin/guptapriya-patch-7\n",
            " * [new branch]      guptapriya-patch-8      -> origin/guptapriya-patch-8\n",
            " * [new branch]      guptapriya-patch-9      -> origin/guptapriya-patch-9\n",
            " * [new branch]      guptapriya-resnet-keras-ds -> origin/guptapriya-resnet-keras-ds\n",
            " * [new branch]      guptapriya-synthetic-input -> origin/guptapriya-synthetic-input\n",
            " * [new branch]      guptapriya-tr-empty-merge-call -> origin/guptapriya-tr-empty-merge-call\n",
            " * [new branch]      guptapriya-tr-loss      -> origin/guptapriya-tr-loss\n",
            " * [new branch]      guptapriya-tr-metrics   -> origin/guptapriya-tr-metrics\n",
            " * [new branch]      guptapriya-tr-no-merge-call -> origin/guptapriya-tr-no-merge-call\n",
            " * [new branch]      guptapriya-transformer-cp -> origin/guptapriya-transformer-cp\n",
            " * [new branch]      haoyuz-warmup           -> origin/haoyuz-warmup\n",
            " * [new branch]      isaprykin-patch-1       -> origin/isaprykin-patch-1\n",
            " * [new branch]      isaprykin-patch-2       -> origin/isaprykin-patch-2\n",
            " * [new branch]      isaprykin-patch-3       -> origin/isaprykin-patch-3\n",
            " * [new branch]      isaprykin-patch-4       -> origin/isaprykin-patch-4\n",
            " * [new branch]      isaprykin-patch-5       -> origin/isaprykin-patch-5\n",
            " * [new branch]      isaprykin-patch-6       -> origin/isaprykin-patch-6\n",
            " * [new branch]      isaprykin-patch-7       -> origin/isaprykin-patch-7\n",
            " * [new branch]      jngiam-bn               -> origin/jngiam-bn\n",
            " * [new branch]      keras-ds                -> origin/keras-ds\n",
            " * [new branch]      keras-models            -> origin/keras-models\n",
            " * [new branch]      keras-validation-freq   -> origin/keras-validation-freq\n",
            " * [new branch]      master                  -> origin/master\n",
            " * [new branch]      mrry-patch-1            -> origin/mrry-patch-1\n",
            " * [new branch]      nas-fix-4               -> origin/nas-fix-4\n",
            " * [new branch]      ncf-estimator-benchmark -> origin/ncf-estimator-benchmark\n",
            " * [new branch]      ncf-keras-contrib-ds    -> origin/ncf-keras-contrib-ds\n",
            " * [new branch]      ncf-keras-debug         -> origin/ncf-keras-debug\n",
            " * [new branch]      ncf-keras-ds            -> origin/ncf-keras-ds\n",
            " * [new branch]      ncf-keras-ds-investigating -> origin/ncf-keras-ds-investigating\n",
            " * [new branch]      ncf_rc_debug            -> origin/ncf_rc_debug\n",
            " * [new branch]      no-batch-from-converge-version -> origin/no-batch-from-converge-version\n",
            " * [new branch]      peterjliu-patch-1       -> origin/peterjliu-patch-1\n",
            " * [new branch]      r1.10.0                 -> origin/r1.10.0\n",
            " * [new branch]      r1.11                   -> origin/r1.11\n",
            " * [new branch]      r1.12.0                 -> origin/r1.12.0\n",
            " * [new branch]      r1.13.0                 -> origin/r1.13.0\n",
            " * [new branch]      r1.4.0                  -> origin/r1.4.0\n",
            " * [new branch]      r1.5                    -> origin/r1.5\n",
            " * [new branch]      r1.6.0                  -> origin/r1.6.0\n",
            " * [new branch]      r1.7.0                  -> origin/r1.7.0\n",
            " * [new branch]      r1.8.0                  -> origin/r1.8.0\n",
            " * [new branch]      r1.8.1                  -> origin/r1.8.1\n",
            " * [new branch]      r1.9.0                  -> origin/r1.9.0\n",
            " * [new branch]      r2.1_model_reference    -> origin/r2.1_model_reference\n",
            " * [new branch]      rachellj218-patch-1     -> origin/rachellj218-patch-1\n",
            " * [new branch]      rachellj218-patch-2     -> origin/rachellj218-patch-2\n",
            " * [new branch]      random-seed             -> origin/random-seed\n",
            " * [new branch]      rdp_accountant          -> origin/rdp_accountant\n",
            " * [new branch]      resnet-ctl-eager        -> origin/resnet-ctl-eager\n",
            " * [new branch]      resnet-device-placement -> origin/resnet-device-placement\n",
            " * [new branch]      resnet-perf             -> origin/resnet-perf\n",
            " * [new branch]      resnet-perf-simple      -> origin/resnet-perf-simple\n",
            " * [new branch]      resnet-upgrade          -> origin/resnet-upgrade\n",
            " * [new branch]      revert-5566-patch-1     -> origin/revert-5566-patch-1\n",
            " * [new branch]      revert-6517-haoyuzhang-revert -> origin/revert-6517-haoyuzhang-revert\n",
            " * [new branch]      revert-6578-rxsang-patch-4 -> origin/revert-6578-rxsang-patch-4\n",
            " * [new branch]      revert-7254-guptapriya-patch-13 -> origin/revert-7254-guptapriya-patch-13\n",
            " * [new branch]      rxsang-patch-1          -> origin/rxsang-patch-1\n",
            " * [new branch]      rxsang-patch-10         -> origin/rxsang-patch-10\n",
            " * [new branch]      rxsang-patch-2          -> origin/rxsang-patch-2\n",
            " * [new branch]      rxsang-patch-3          -> origin/rxsang-patch-3\n",
            " * [new branch]      rxsang-patch-4          -> origin/rxsang-patch-4\n",
            " * [new branch]      rxsang-patch-5          -> origin/rxsang-patch-5\n",
            " * [new branch]      rxsang-patch-6          -> origin/rxsang-patch-6\n",
            " * [new branch]      rxsang-patch-7          -> origin/rxsang-patch-7\n",
            " * [new branch]      rxsang-patch-8          -> origin/rxsang-patch-8\n",
            " * [new branch]      rxsang-patch-8-1        -> origin/rxsang-patch-8-1\n",
            " * [new branch]      rxsang-patch-9          -> origin/rxsang-patch-9\n",
            " * [new branch]      saberkun                -> origin/saberkun\n",
            " * [new branch]      segmentation_blogpost   -> origin/segmentation_blogpost\n",
            " * [new branch]      serving_blogpost        -> origin/serving_blogpost\n",
            " * [new branch]      shakespeare             -> origin/shakespeare\n",
            " * [new branch]      shizhiw                 -> origin/shizhiw\n",
            " * [new branch]      shizhiw_20181026        -> origin/shizhiw_20181026\n",
            " * [new branch]      test-bert-int64         -> origin/test-bert-int64\n",
            " * [new branch]      test-bert-tfwhile       -> origin/test-bert-tfwhile\n",
            " * [new branch]      testtest                -> origin/testtest\n",
            " * [new branch]      textsumpy3fix           -> origin/textsumpy3fix\n",
            " * [new branch]      tf_2_0_rc0              -> origin/tf_2_0_rc0\n",
            " * [new branch]      tf_2_0_rc1              -> origin/tf_2_0_rc1\n",
            " * [new branch]      tf_2_1_reference        -> origin/tf_2_1_reference\n",
            " * [new branch]      tfboyd-patch-1          -> origin/tfboyd-patch-1\n",
            " * [new branch]      tianli-patch-1          -> origin/tianli-patch-1\n",
            " * [new branch]      todo-names              -> origin/todo-names\n",
            " * [new branch]      todos                   -> origin/todos\n",
            " * [new branch]      transformer-softmax-fp32 -> origin/transformer-softmax-fp32\n",
            " * [new branch]      unify-benchmark         -> origin/unify-benchmark\n",
            " * [new branch]      yeqing-detection-reamde -> origin/yeqing-detection-reamde\n",
            " * [new branch]      yuefengz_bert           -> origin/yuefengz_bert\n",
            " * [new branch]      zongweiz-multi-worker   -> origin/zongweiz-multi-worker\n",
            " * [new branch]      zongweiz-profile-bert   -> origin/zongweiz-profile-bert\n",
            " * [new tag]         v.1.6.0                 -> v.1.6.0\n",
            " * [new tag]         v1.10.0                 -> v1.10.0\n",
            " * [new tag]         v1.11                   -> v1.11\n",
            " * [new tag]         v1.12.0                 -> v1.12.0\n",
            " * [new tag]         v1.13.0                 -> v1.13.0\n",
            " * [new tag]         v1.4.0                  -> v1.4.0\n",
            " * [new tag]         v1.7.0                  -> v1.7.0\n",
            " * [new tag]         v1.9.0                  -> v1.9.0\n",
            " * [new tag]         v2.0                    -> v2.0\n",
            " * [new tag]           v1.8.0                  -> v1.8.0\n",
            " * [new tag]           v1.8.1                  -> v1.8.1\n",
            "From https://github.com/tensorflow/models\n",
            " * branch              master     -> FETCH_HEAD\n",
            "/content\n",
            "Collecting virtualenv\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/77/6a86ef945ad39aae34aed4cc1ae4a2f941b9870917a974ed7c5b6f137188/virtualenv-16.7.8-py2.py3-none-any.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 3.5MB/s \n",
            "\u001b[?25hInstalling collected packages: virtualenv\n",
            "Successfully installed virtualenv-16.7.8\n",
            "Using base prefix '/usr'\n",
            "New python executable in /content/venv/bin/python3\n",
            "Also creating executable in /content/venv/bin/python\n",
            "Installing setuptools, pip, wheel...\n",
            "done.\n",
            "Running virtualenv with interpreter /usr/bin/python2.7\n",
            "Already using interpreter /usr/bin/python2.7\n",
            "New python executable in /content/temp-python/bin/python2.7\n",
            "Also creating executable in /content/temp-python/bin/python\n",
            "Installing setuptools, pip, wheel...\n",
            "done.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following packages will be REMOVED:\n",
            "  libnvidia-common-430\n",
            "0 upgraded, 0 newly installed, 1 to remove and 32 not upgraded.\n",
            "After this operation, 35.8 kB disk space will be freed.\n",
            "(Reading database ... 145652 files and directories currently installed.)\n",
            "Removing libnvidia-common-430 (430.50-0ubuntu0.18.04.2) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "zip is already the newest version (3.0-11build1).\n",
            "g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n",
            "g++ set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  openjdk-11-jdk-headless\n",
            "Suggested packages:\n",
            "  openjdk-11-demo openjdk-11-source visualvm\n",
            "The following NEW packages will be installed:\n",
            "  openjdk-11-jdk openjdk-11-jdk-headless\n",
            "0 upgraded, 2 newly installed, 0 to remove and 32 not upgraded.\n",
            "Need to get 193 MB of archives.\n",
            "After this operation, 203 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openjdk-11-jdk-headless amd64 11.0.4+11-1ubuntu2~18.04.3 [191 MB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 openjdk-11-jdk amd64 11.0.4+11-1ubuntu2~18.04.3 [2,173 kB]\n",
            "Fetched 193 MB in 7s (26.2 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 2.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package openjdk-11-jdk-headless:amd64.\n",
            "(Reading database ... 145647 files and directories currently installed.)\n",
            "Preparing to unpack .../openjdk-11-jdk-headless_11.0.4+11-1ubuntu2~18.04.3_amd64.deb ...\n",
            "Unpacking openjdk-11-jdk-headless:amd64 (11.0.4+11-1ubuntu2~18.04.3) ...\n",
            "Selecting previously unselected package openjdk-11-jdk:amd64.\n",
            "Preparing to unpack .../openjdk-11-jdk_11.0.4+11-1ubuntu2~18.04.3_amd64.deb ...\n",
            "Unpacking openjdk-11-jdk:amd64 (11.0.4+11-1ubuntu2~18.04.3) ...\n",
            "Setting up openjdk-11-jdk-headless:amd64 (11.0.4+11-1ubuntu2~18.04.3) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeprscan to provide /usr/bin/jdeprscan (jdeprscan) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jimage to provide /usr/bin/jimage (jimage) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jlink to provide /usr/bin/jlink (jlink) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jmod to provide /usr/bin/jmod (jmod) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jshell to provide /usr/bin/jshell (jshell) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jaotc to provide /usr/bin/jaotc (jaotc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jhsdb to provide /usr/bin/jhsdb (jhsdb) in auto mode\n",
            "Setting up openjdk-11-jdk:amd64 (11.0.4+11-1ubuntu2~18.04.3) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-11-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n",
            "--2019-12-01 14:40:10--  https://github.com/bazelbuild/bazel/releases/download/1.0.0/bazel-1.0.0-installer-linux-x86_64.sh\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/7f304f80-eb59-11e9-94f6-6f4d6a8f6795?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191201T144010Z&X-Amz-Expires=300&X-Amz-Signature=b6db018f761abce5ef45c101b67c6aa171f5ef38b91db8359af1ffe5b5802226&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-1.0.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2019-12-01 14:40:10--  https://github-production-release-asset-2e65be.s3.amazonaws.com/20773773/7f304f80-eb59-11e9-94f6-6f4d6a8f6795?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20191201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20191201T144010Z&X-Amz-Expires=300&X-Amz-Signature=b6db018f761abce5ef45c101b67c6aa171f5ef38b91db8359af1ffe5b5802226&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dbazel-1.0.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.137.156\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.137.156|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43815288 (42M) [application/octet-stream]\n",
            "Saving to: ‘bazel-1.0.0-installer-linux-x86_64.sh’\n",
            "\n",
            "bazel-1.0.0-install 100%[===================>]  41.79M  70.6MB/s    in 0.6s    \n",
            "\n",
            "2019-12-01 14:40:11 (70.6 MB/s) - ‘bazel-1.0.0-installer-linux-x86_64.sh’ saved [43815288/43815288]\n",
            "\n",
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# Release 1.0.0 (2019-10-10)\n",
            "\n",
            "Baseline: 97a82646dadd93bf52d47828bda42e3383b657c6\n",
            "\n",
            "Cherry picks:\n",
            "\n",
            "   + a0e3bb207fe2044120a2555a37162ee1f2b17500:\n",
            "     Remove support for authentication and .netrc\n",
            "   + ada2c55dcc106cd55bafbbe5d9a966e21e4770e0:\n",
            "     Add explicit --sdk argument to xcrun calls\n",
            "   + 847df729528f6e5919ec8374247eadf792cba544:\n",
            "     toolchain_vanilla: Unset source and target language level\n",
            "     versions\n",
            "   + 5cfa0303d6ac3b5bd031ff60272ce80a704af8c2:\n",
            "     Update java_tools version to javac11-v5.1.\n",
            "\n",
            "Incompatible changes:\n",
            "\n",
            "  - Python, Windows: the\n",
            "    --[no]incompatible_windows_escape_python_args is no longer\n",
            "    supported. (It was flipped to true in Bazel 0.27.0)\n",
            "  - --incompatible_use_native_patch is enabled by default\n",
            "  - Windows: --incompatible_windows_bashless_run_command is now true\n",
            "    by default, meaning \"bazel run //foo:bin\" will run the binary as\n",
            "    a subprocess of the Bazel client. (When the flag is false, the\n",
            "    binary is executed as a subprocess of Bash.)\n",
            "  - Windows: --incompatible_windows_native_test_wrapper is enabled by\n",
            "    default\n",
            "\n",
            "New features:\n",
            "\n",
            "  - Genrule now supports `cmd_bash`, `cmd_ps`, `cmd_bat` attributes.\n",
            "    More details at\n",
            "    https://docs.bazel.build/versions/master/be/general.html#genrule.c\n",
            "    md\n",
            "  - config_setting can now check multiple values on \"--foo=firstVal\n",
            "    --foo=secondVal ...\"-style flags\n",
            "  - tags: use `--experimental_allow_tags_propagation` flag to\n",
            "    propagate tags to the action's execution requirements from\n",
            "    targets. Such tags should start with: `no-`, `requires-`,\n",
            "    `supports-`, `block-`, `disable-`, `cpu:`. See #8830 for details.\n",
            "  - Users can now get generated def file from cc_library via\n",
            "    \"def_file\" output group on Windows.\n",
            "  - Platform-specific bazelrc: with --enable_platform_specific_config\n",
            "    you can\n",
            "    enable flags in bazelrc according to your host platform.\n",
            "  - tags: use `--experimental_allow_tags_propagation` flag to\n",
            "    propagate tags to the action's execution requirements from\n",
            "    cc_library or cc_binary targets. Such tags should start with:\n",
            "    `no-`, `requires-`, `supports-`, `block-`, `disable-`, `cpu:`.\n",
            "    See #8830 for details.\n",
            "  - tags: use --experimental_allow_tags_propagation flag to propagate\n",
            "    tags to the action's execution requirements from java targets.\n",
            "    Such tags should start with: no-, requires-, supports-, block-,\n",
            "    disable-, cpu:. See #8830 for details.\n",
            "\n",
            "Important changes:\n",
            "\n",
            "  - Bazel Android builds now use aapt2 by default. To revert to aapt,\n",
            "    set `--android_aapt=aapt`.\n",
            "  - Make either --subcommands or --verbose_failures imply\n",
            "    --materialize_param_files\n",
            "  - Bazel Android builds now use aapt2 by default. To revert to aapt,\n",
            "    set `--an...\n",
            "    RELNOTES: None\n",
            "  - by default all remote connections considered to be via `gRPC`\n",
            "    with TLS enabled, unless other specified. To disable TLS use\n",
            "    `grpc://` prefix for you endpoints. All remote connections via\n",
            "    `gRPC` affected - `--remote_cache`, `--remote_executor` or\n",
            "    `--bes_backend`. http cache/executor is not affected. See #8061\n",
            "    for details.\n",
            "  - cc_* rules support non-transitive defines through a\n",
            "    'local_defines' attribute.\n",
            "  - Enable\n",
            "    incompatible_disallow_rule_execution_platform_constraints_allowed\n",
            "    by default (https://github.com/bazelbuild/bazel/issues/8136).\n",
            "  - incompatible_disallow_split_empty_separator is enabled by default\n",
            "  - Fixed Android build issues with aapt2 on Windows. See the [GitHub\n",
            "    issue](https://github.com/bazelbuild/bazel/issues/9102) for more\n",
            "    information.\n",
            "  - --incompatible_disable_static_cc_toolchains has been flipped. See\n",
            "    https://github.com/bazelbuild/bazel/issues/8546.\n",
            "  - --remote_default_platform_properties has been deprecated in favor\n",
            "    of --remote_default_exec_properties.\n",
            "  - The --incompatible_make_thinlto_command_lines_standalone flag has\n",
            "    been flipped, see https://github.com/bazelbuild/bazel/issues/6791\n",
            "    for more information.\n",
            "  - The --incompatible_use_specific_tool_files flag has been flipped.\n",
            "    See https://github.com/bazelbuild/bazel/pull/9126 for more\n",
            "    information.\n",
            "  - Clarify default visibility.\n",
            "  - Enables incompatible_auto_configure_host_platform\n",
            "  - New incompatible flag --incompatible_disable_depset_items\n",
            "    disables the \"items\" parameter in the Starlark depset\n",
            "    constructor. Use \"direct\" and \"transitive\" parameters instead.\n",
            "  - --incompatible_assignment_identifiers_have_local_scope is enabled\n",
            "  - incompatible_disable_partition_default_parameter is enabled by\n",
            "    default ()\n",
            "  - incompatible_restrict_attribute_names is enabled\n",
            "    (https://github.com/bazelbuild/bazel/issues/6437)\n",
            "  - The --incompatible_disable_nocopts flag has been flipped. See\n",
            "    https://github.com/bazelbuild/bazel/issues/8546 for more\n",
            "    information.\n",
            "  - Deprecated Java-Starlark API java_common.create_provider is\n",
            "    removed. JavaInfo() legacy args (actions, sources, source_jars,\n",
            "    use_ijar, java_toolchain, host_javabase) are removed.\n",
            "  - The flag incompatible_disallow_hashing_frozen_mutables is enabled\n",
            "    (https://github.com/bazelbuild/bazel/issues/7800)\n",
            "  - `maven_jar` and `maven_server` now disallow using plain HTTP URLs\n",
            "    without a specified checksum. If you are still using `maven_jar`,\n",
            "    consider migrating to\n",
            "    [`rules_jvm_external`](https://github.com/bazelbuild/rules_jvm_ext\n",
            "    ernal) for transitive dependency management. See\n",
            "    [#8607](https://github.com/bazelbuild/bazel/issues/8607) for more\n",
            "    information.\n",
            "  - Added `sha256` and `sha256_src` attributes to `maven_jar`. Please\n",
            "    consider migrating to SHA-256 as SHA-1 has been deemed\n",
            "    cryptographically insecure ([https://shattered.io]()). Or, use\n",
            "    [`rules_jvm_external`](https://github.com/bazelbuild/rules_jvm_ext\n",
            "    ernal) to manage your transitive Maven dependencies with artifact\n",
            "    pinning and SHA-256 verification support.\n",
            "  - introducing per-target exec_properties\n",
            "  - Bazel now supports ThinLTO builds on Linux for Clang versions >=\n",
            "    6.0. ThinLTO can be enabled through --features=thin_lto\n",
            "  - The Target.output_group field in Starlark is removed. Use\n",
            "    OutputGroupInfo instead. See\n",
            "    https://github.com/bazelbuild/bazel/issues/7949 for details.\n",
            "  - Make a number of parameters of Starlark builtin functions\n",
            "    positional-only (as opposed to specifiable by keyword). See\n",
            "    https://github.com/bazelbuild/bazel/issues/8147 for details.\n",
            "  - incompatible_skip_genfiles_symlink is enabled by default (#8651)\n",
            "  - Change Pruned events will fire immediately after being checked.\n",
            "  - --incompatible_remove_legacy_whole_archive has been flipped. See\n",
            "    https://github.com/bazelbuild/bazel/issues/7362 for more\n",
            "    information\n",
            "\n",
            "This release contains contributions from many people at Google, as well as Adam Liddell, Alessandro Patti, Arshabh Kumar Agarwal, Artem Pelenitsyn, Artem Zinnatullin, Benjamin Peterson, David Ostrovsky, Emmanuel Goh, Farhim Ferdous, George Gensure, iirina, Keith Smiley, Kiril Videlov, Laurent Le Brun, Mantas Sakalauskas, Marwan Tammam, Matt Mukerjee, panzhongxian, Shachar Anchelovich, Stepan Koltsov, Stephan Wolski, Travis Clarke, Yannic Bonenberger, Yuta Saito.\n",
            "\n",
            "## Build information\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/9c257df)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/root/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /root/.bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n",
            "Collecting tensorflow==1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/58/b71480f9ec9d08d581d672a81b15ab5fec36a5fcda2093558a23614d8468/tensorflow-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (44.5MB)\n",
            "\u001b[K     |████████████████████████████████| 44.5MB 176kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (1.17.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (0.33.6)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (3.10.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.0.0) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.1.0->tensorflow==1.0.0) (41.6.0)\n",
            "\u001b[31mERROR: stable-baselines 2.2.1 has requirement tensorflow>=1.5.0, but you'll have tensorflow 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: magenta 0.3.19 has requirement tensorflow>=1.12.0, but you'll have tensorflow 1.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorflow-1.0.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.17.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "/usr/lib/python3.6/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Downloading 0B3laN3vvvSD2WWxuR3VRQzhycWM into /content/Pretrained-Show-and-Tell-model/model.ckpt-1000000.data-00000-of-00001... Done.\n",
            "Downloading 0B3laN3vvvSD2T1RPeDA5djJ6bFE into /content/Pretrained-Show-and-Tell-model/model.ckpt-2000000.data-00000-of-00001... Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUSfG34JgXf4",
        "colab_type": "code",
        "outputId": "7d0b5ed6-bf9d-4b67-ebb1-7deeb14f22e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# the code executed when server is running \n",
        "#########################################################################\n",
        "# Object Detection part\n",
        "#########################################################################\n",
        "def inferrence(im, mode='labels'):\n",
        "  outputs = predictor(im)\n",
        "\n",
        "  #this create text labels from int labels\n",
        "  def _create_text_labels(classes, scores, class_names):\n",
        "      \"\"\"\n",
        "      Args:\n",
        "          classes (list[int] or None):\n",
        "          scores (list[float] or None):\n",
        "          class_names (list[str] or None):\n",
        "\n",
        "      Returns:\n",
        "          list[str] or None\n",
        "      \"\"\"\n",
        "      # we take items over score_threshold\n",
        "      score_threshold = 0.8\n",
        "      labels = None\n",
        "      if classes is not None and class_names is not None and len(class_names) > 1:\n",
        "          labels = [class_names[i] for i in classes]\n",
        "      if scores is not None:\n",
        "          if labels is None:\n",
        "              labels = [\"{:.0f}%\".format(s * 100) for s in scores]\n",
        "          else:\n",
        "              labels = [\"{} {:.0f}%\".format(l, s * 100) for l, s in zip(labels, scores) if score_threshold >= 0.8]\n",
        "      return labels\n",
        "\n",
        "  # used like this in 'draw_instance_predictions(self, predictions)' (this 'self' is a Visualizer object)\n",
        "  # scores = predictions.scores if predictions.has(\"scores\") else None\n",
        "  # classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n",
        "  # labels = _create_text_labels(classes, scores, self.metadata.get(\"thing_classes\", None))\n",
        "\n",
        "  v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "\n",
        "  # We can use `Visualizer` to draw the predictions on the image.\n",
        "\n",
        "  if mode == 'segmentation':\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(v.get_image()[:, :, ::-1])\n",
        "  elif mode == 'labels':\n",
        "    # variable 'labels' is text labels included in image\n",
        "    predictions = outputs[\"instances\"].to(\"cpu\")\n",
        "    scores = predictions.scores if predictions.has(\"scores\") else None\n",
        "    classes = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n",
        "    labels = _create_text_labels(classes, scores, v.metadata.get(\"thing_classes\", None))\n",
        "    labels = [x.split()[0] for x in labels]\n",
        "    labels = list(OrderedDict((element, None) for element in labels))\n",
        "    return labels\n",
        "\n",
        "#########################################################################\n",
        "# TTS part\n",
        "#########################################################################\n",
        "def inferrence_tts(text):\n",
        "  print(\"Audio synthesis with latest record\")\n",
        "  in_fpath = Path(\"audio.wav\")\n",
        "  reprocessed_wav = encoder.preprocess_wav(in_fpath)\n",
        "  original_wav, sampling_rate = librosa.load(in_fpath)\n",
        "  preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)\n",
        "  embed = encoder.embed_utterance(preprocessed_wav)\n",
        "  print(\"Synthesizing new audio...\")\n",
        "  with io.capture_output() as captured:\n",
        "    specs = synthesizer.synthesize_spectrograms([text], [embed])\n",
        "  generated_wav = vocoder.infer_waveform(specs[0])\n",
        "  generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode=\"constant\")\n",
        "  # display(Audio(generated_wav, rate=synthesizer.sample_rate))\n",
        "  #librosa.output.write_wav(\"./result.wav\", generated_wav, synthesizer.sample_rate)\n",
        "  import numpy as np\n",
        "  from scipy.io.wavfile import write\n",
        "  write('first_sine_wave.wav', sps, generated_wav)\n",
        "  return\n",
        "\n",
        "#########################################################################\n",
        "# OCR part\n",
        "#########################################################################\n",
        "def inferrence_ocr(im_path):\n",
        "  import sys\n",
        "  print(\"inside inference\")\n",
        "  os.system('tesseract '+im_path+' output')\n",
        "\n",
        "#########################################################################\n",
        "# Image Captioning part\n",
        "#########################################################################\n",
        "import subprocess as sp\n",
        "from requests import get\n",
        "\n",
        "def download_img(url):\n",
        "  %cd /content\n",
        "  download(url,\"hello.jpg\")\n",
        "\n",
        "def download(url, file_name):\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        response = get(url)\n",
        "        file.write(response.content)\n",
        "        file.close()\n",
        "\n",
        "def run_img_captioning():\n",
        "    CHECKPOINT_PATH=\"/content/Pretrained-Show-and-Tell-model/model.ckpt-2000000\";\n",
        "    VOCAB_FILE=\"/content/Pretrained-Show-and-Tell-model/word_counts.txt\";\n",
        "    IMAGE_FILE=\"/content/pics/hello.jpg\";\n",
        "\n",
        "    if os.path.exists('/result.txt'):\n",
        "        os.remove('/result.txt')\n",
        "\n",
        "    %cd /content/img_caption/research/im2txt\n",
        "    !bazel build -c opt im2txt/run_inference\n",
        "\n",
        "    !bazel-bin/im2txt/run_inference \\\n",
        "        --checkpoint_path=$CHECKPOINT_PATH \\\n",
        "        --vocab_file=$VOCAB_FILE \\\n",
        "        --input_files=$IMAGE_FILE\n",
        "\n",
        "    g=open('/result.txt')\n",
        "    line=g.readline()\n",
        "    # print(line)\n",
        "    g.close()\n",
        "    return line\n",
        "\n",
        "#code for actually running server\n",
        "from flask import Flask\n",
        "from flask import request\n",
        "from flask import jsonify\n",
        "from flask import make_response\n",
        "from flask import send_from_directory\n",
        "import os\n",
        "from flask_ngrok import run_with_ngrok\n",
        "app = Flask(__name__)\n",
        "UPLOAD_FOLDER = './pics'\n",
        "if not os.path.exists(UPLOAD_FOLDER):\n",
        "  os.mkdir(UPLOAD_FOLDER)\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "run_with_ngrok(app)   #starts ngrok when the app is run\n",
        "\n",
        "#server code which handles request for object detection\n",
        "@app.route('/picture', methods=['POST', 'GET'])\n",
        "def upload_file():\n",
        "    if request.method == 'POST':\n",
        "        file = request.files['file']\n",
        "        if file:\n",
        "            filename = \"hello.jpg\"\n",
        "            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
        "            im = cv2.imread(\"./pics/hello.jpg\")\n",
        "            result = inferrence(im)\n",
        "            print(result)\n",
        "            text = \"\"\n",
        "            if len(result) == 0:\n",
        "              text = \"Unknown object\"\n",
        "            else:\n",
        "              text = ', '.join(result)\n",
        "            print(text)\n",
        "            return jsonify({'result':text})\n",
        "\n",
        "#server code which handles request for OCR\n",
        "@app.route('/swipeDown', methods=['POST', 'GET'])\n",
        "def upload_f():\n",
        "    if request.method == 'POST':\n",
        "        file = request.files['file']\n",
        "        if file:\n",
        "            print(\"in OCR\")\n",
        "            filename = \"hello.jpg\"\n",
        "            file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
        "            inferrence_ocr(\"./pics/hello.jpg\")\n",
        "            with open('./output.txt', 'r') as content_file:\n",
        "              content = content_file.read()\n",
        "            text = \"\"\n",
        "            if len(content) == 0:\n",
        "              text = \"text not detected\"\n",
        "            else:\n",
        "              text = content\n",
        "            print(text)\n",
        "        return jsonify({'result':text})\n",
        "\n",
        "#server code which handles request for Image Captioning \n",
        "@app.route('/swipeUp', methods=['POST', 'GET'])\n",
        "def upload_file2():\n",
        "    if request.method == 'POST':\n",
        "      file = request.files['file']\n",
        "      if file:\n",
        "          filename = \"hello.jpg\"\n",
        "          file.save(os.path.join(app.config['UPLOAD_FOLDER'], filename))\n",
        "          im = cv2.imread(\"/content/pics/hello.jpg\")\n",
        "          result = run_img_captioning()\n",
        "          print(result)\n",
        "          text = \"\"\n",
        "          if len(result) == 0:\n",
        "            text = \"Unknown object\"\n",
        "          else:\n",
        "            text = result\n",
        "          print(text)\n",
        "          return jsonify({'result':text})\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " * Running on http://e220492d.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [01/Dec/2019 14:44:37] \"\u001b[37mPOST /picture HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['mouse', 'keyboard', 'tv']\n",
            "mouse, keyboard, tv\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [01/Dec/2019 14:44:45] \"\u001b[37mPOST /picture HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['chair', 'tv', 'laptop', 'cup', 'mouse', 'bird', 'keyboard', 'dining']\n",
            "chair, tv, laptop, cup, mouse, bird, keyboard, dining\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}